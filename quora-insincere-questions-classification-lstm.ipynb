{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025897,
     "end_time": "2021-02-09T18:29:55.231232",
     "exception": false,
     "start_time": "2021-02-09T18:29:55.205335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Quora Insicere Questions Classification\n",
    "\n",
    "**Experiment 1:**\n",
    "- Without pretrained + LSTM\n",
    "\n",
    "**Experiment 2:**\n",
    "- With pretrained(Google news pretrained Embeddings ) + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:29:55.286081Z",
     "iopub.status.busy": "2021-02-09T18:29:55.285419Z",
     "iopub.status.idle": "2021-02-09T18:29:56.756512Z",
     "shell.execute_reply": "2021-02-09T18:29:56.755422Z"
    },
    "papermill": {
     "duration": 1.500876,
     "end_time": "2021-02-09T18:29:56.756722",
     "exception": false,
     "start_time": "2021-02-09T18:29:55.255846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### importing the libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import KeyedVectors\n",
    "import re ## Regular expresssions\n",
    "from nltk import word_tokenize\n",
    "from sklearn import metrics\n",
    "from gensim.models import KeyedVectors\n",
    "import operator\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:29:56.819704Z",
     "iopub.status.busy": "2021-02-09T18:29:56.819137Z",
     "iopub.status.idle": "2021-02-09T18:30:01.271855Z",
     "shell.execute_reply": "2021-02-09T18:30:01.270776Z"
    },
    "papermill": {
     "duration": 4.487707,
     "end_time": "2021-02-09T18:30:01.272019",
     "exception": false,
     "start_time": "2021-02-09T18:29:56.784312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### reading the data files\n",
    "test_data=pd.read_csv(\"../input/quora-insincere-questions-classification/test.csv\")\n",
    "train_data=pd.read_csv(\"../input/quora-insincere-questions-classification/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:30:01.336443Z",
     "iopub.status.busy": "2021-02-09T18:30:01.335619Z",
     "iopub.status.idle": "2021-02-09T18:30:01.343541Z",
     "shell.execute_reply": "2021-02-09T18:30:01.343937Z"
    },
    "papermill": {
     "duration": 0.047092,
     "end_time": "2021-02-09T18:30:01.344070",
     "exception": false,
     "start_time": "2021-02-09T18:30:01.296978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:30:01.402585Z",
     "iopub.status.busy": "2021-02-09T18:30:01.401958Z",
     "iopub.status.idle": "2021-02-09T18:30:01.405249Z",
     "shell.execute_reply": "2021-02-09T18:30:01.405638Z"
    },
    "papermill": {
     "duration": 0.036363,
     "end_time": "2021-02-09T18:30:01.405755",
     "exception": false,
     "start_time": "2021-02-09T18:30:01.369392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
       "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
       "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n",
       "3  000086e4b7e1c7146103                             Who are entrepreneurs?\n",
       "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:30:01.463520Z",
     "iopub.status.busy": "2021-02-09T18:30:01.462549Z",
     "iopub.status.idle": "2021-02-09T18:30:03.108246Z",
     "shell.execute_reply": "2021-02-09T18:30:03.107177Z"
    },
    "papermill": {
     "duration": 1.677114,
     "end_time": "2021-02-09T18:30:03.108379",
     "exception": false,
     "start_time": "2021-02-09T18:30:01.431265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Training set : (1044897, 3)\n",
      "Shape of the Validation set : (261225, 3)\n"
     ]
    }
   ],
   "source": [
    "### splitting the dataset in to the training set and validation set \n",
    "train,val=train_test_split(train_data,test_size=0.2,stratify=train_data.target,random_state=123)\n",
    "print(\"Shape of the Training set :\",train.shape)\n",
    "print(\"Shape of the Validation set :\",val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:30:03.166252Z",
     "iopub.status.busy": "2021-02-09T18:30:03.165709Z",
     "iopub.status.idle": "2021-02-09T18:33:42.808631Z",
     "shell.execute_reply": "2021-02-09T18:33:42.807683Z"
    },
    "papermill": {
     "duration": 219.673921,
     "end_time": "2021-02-09T18:33:42.808801",
     "exception": false,
     "start_time": "2021-02-09T18:30:03.134880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ../input/quora-insincere-questions-classification/embeddings.zip\r\n",
      "   creating: GoogleNews-vectors-negative300/\r\n",
      "   creating: glove.840B.300d/\r\n",
      "   creating: paragram_300_sl999/\r\n",
      "   creating: wiki-news-300d-1M/\r\n",
      "  inflating: glove.840B.300d/glove.840B.300d.txt  \r\n",
      "  inflating: GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin  \r\n",
      "  inflating: wiki-news-300d-1M/wiki-news-300d-1M.vec  \r\n",
      "  inflating: paragram_300_sl999/README.txt  \r\n",
      "  inflating: paragram_300_sl999/paragram_300_sl999.txt  \r\n",
      "CPU times: user 2.99 s, sys: 649 ms, total: 3.64 s\n",
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### unzipping all the pretrained embeddings\n",
    "!unzip ../input/quora-insincere-questions-classification/embeddings.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.042548,
     "end_time": "2021-02-09T18:33:48.233370",
     "exception": false,
     "start_time": "2021-02-09T18:33:46.190822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Experiment 1: With out Pretrained Embeddings + LSTM\n",
    "- here we will train the embeddings From scratch \n",
    "\n",
    "**steps to do this**\n",
    "        - firstly preprocess the data\n",
    "        - Get vocabulary of training corpus\n",
    "        - Convert the text to sequence (one hot formate)\n",
    "        - pad sequence to maxlength this has to be fixed length\n",
    "        - we will input the padded sequence to the Embedding layer in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.086198,
     "end_time": "2021-02-09T18:33:50.027656",
     "exception": false,
     "start_time": "2021-02-09T18:33:49.941458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### step:1 Preprocess the data\n",
    "**Experiment 1.1 : with out preprocess**\n",
    "        - here i am not going to preprocess much here\n",
    "        - becz i am just want the sequence as it was \n",
    "        - here we do just normalization i.e converting from uppercase to lowercase letters\n",
    "\n",
    "**Experiment 1.2 : With Preprocess**\n",
    "\n",
    "    - converting the number to unique code\n",
    "    - Applying the contractions \n",
    "    - removing the punctuation marks\n",
    "    - Normalizing the text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:33:50.239178Z",
     "iopub.status.busy": "2021-02-09T18:33:50.238265Z",
     "iopub.status.idle": "2021-02-09T18:33:50.468736Z",
     "shell.execute_reply": "2021-02-09T18:33:50.469467Z"
    },
    "papermill": {
     "duration": 0.358602,
     "end_time": "2021-02-09T18:33:50.469691",
     "exception": false,
     "start_time": "2021-02-09T18:33:50.111089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How did Quebec nationalists see their province as a nation in the 1960s?\n"
     ]
    }
   ],
   "source": [
    "print(train.question_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:33:50.690039Z",
     "iopub.status.busy": "2021-02-09T18:33:50.688781Z",
     "iopub.status.idle": "2021-02-09T18:33:50.752263Z",
     "shell.execute_reply": "2021-02-09T18:33:50.771242Z"
    },
    "papermill": {
     "duration": 0.162668,
     "end_time": "2021-02-09T18:33:50.771521",
     "exception": false,
     "start_time": "2021-02-09T18:33:50.608853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contractions={\"I'm\": 'I am',\n",
    " \"I'm'a\": 'I am about to',\n",
    " \"I'm'o\": 'I am going to',\n",
    " \"I've\": 'I have',\n",
    " \"I'll\": 'I will',\n",
    " \"I'll've\": 'I will have',\n",
    " \"I'd\": 'I would',\n",
    " \"I'd've\": 'I would have',\n",
    " 'Whatcha': 'What are you',\n",
    " \"amn't\": 'am not',\n",
    " \"ain't\": 'are not',\n",
    " \"aren't\": 'are not',\n",
    " \"'cause\": 'because',\n",
    " \"can't\": 'can not',\n",
    " \"can't've\": 'can not have',\n",
    " \"could've\": 'could have',\n",
    " \"couldn't\": 'could not',\n",
    " \"couldn't've\": 'could not have',\n",
    " \"daren't\": 'dare not',\n",
    " \"daresn't\": 'dare not',\n",
    " \"dasn't\": 'dare not',\n",
    " \"didn't\": 'did not',\n",
    " 'didn’t': 'did not',\n",
    " \"don't\": 'do not',\n",
    " 'don’t': 'do not',\n",
    " \"doesn't\": 'does not',\n",
    " \"e'er\": 'ever',\n",
    " \"everyone's\": 'everyone is',\n",
    " 'finna': 'fixing to',\n",
    " 'gimme': 'give me',\n",
    " \"gon't\": 'go not',\n",
    " 'gonna': 'going to',\n",
    " 'gotta': 'got to',\n",
    " \"hadn't\": 'had not',\n",
    " \"hadn't've\": 'had not have',\n",
    " \"hasn't\": 'has not',\n",
    " \"haven't\": 'have not',\n",
    " \"he've\": 'he have',\n",
    " \"he's\": 'he is',\n",
    " \"he'll\": 'he will',\n",
    " \"he'll've\": 'he will have',\n",
    " \"he'd\": 'he would',\n",
    " \"he'd've\": 'he would have',\n",
    " \"here's\": 'here is',\n",
    " \"how're\": 'how are',\n",
    " \"how'd\": 'how did',\n",
    " \"how'd'y\": 'how do you',\n",
    " \"how's\": 'how is',\n",
    " \"how'll\": 'how will',\n",
    " \"isn't\": 'is not',\n",
    " \"it's\": 'it is',\n",
    " \"'tis\": 'it is',\n",
    " \"'twas\": 'it was',\n",
    " \"it'll\": 'it will',\n",
    " \"it'll've\": 'it will have',\n",
    " \"it'd\": 'it would',\n",
    " \"it'd've\": 'it would have',\n",
    " 'kinda': 'kind of',\n",
    " \"let's\": 'let us',\n",
    " 'luv': 'love',\n",
    " \"ma'am\": 'madam',\n",
    " \"may've\": 'may have',\n",
    " \"mayn't\": 'may not',\n",
    " \"might've\": 'might have',\n",
    " \"mightn't\": 'might not',\n",
    " \"mightn't've\": 'might not have',\n",
    " \"must've\": 'must have',\n",
    " \"mustn't\": 'must not',\n",
    " \"mustn't've\": 'must not have',\n",
    " \"needn't\": 'need not',\n",
    " \"needn't've\": 'need not have',\n",
    " \"ne'er\": 'never',\n",
    " \"o'\": 'of',\n",
    " \"o'clock\": 'of the clock',\n",
    " \"ol'\": 'old',\n",
    " \"oughtn't\": 'ought not',\n",
    " \"oughtn't've\": 'ought not have',\n",
    " \"o'er\": 'over',\n",
    " \"shan't\": 'shall not',\n",
    " \"sha'n't\": 'shall not',\n",
    " \"shalln't\": 'shall not',\n",
    " \"shan't've\": 'shall not have',\n",
    " \"she's\": 'she is',\n",
    " \"she'll\": 'she will',\n",
    " \"she'd\": 'she would',\n",
    " \"she'd've\": 'she would have',\n",
    " \"should've\": 'should have',\n",
    " \"shouldn't\": 'should not',\n",
    " \"shouldn't've\": 'should not have',\n",
    " \"so've\": 'so have',\n",
    " \"so's\": 'so is',\n",
    " \"somebody's\": 'somebody is',\n",
    " \"someone's\": 'someone is',\n",
    " \"something's\": 'something is',\n",
    " 'sux': 'sucks',\n",
    " \"that're\": 'that are',\n",
    " \"that's\": 'that is',\n",
    " \"that'll\": 'that will',\n",
    " \"that'd\": 'that would',\n",
    " \"that'd've\": 'that would have',\n",
    " 'em': 'them',\n",
    " \"there're\": 'there are',\n",
    " \"there's\": 'there is',\n",
    " \"there'll\": 'there will',\n",
    " \"there'd\": 'there would',\n",
    " \"there'd've\": 'there would have',\n",
    " \"these're\": 'these are',\n",
    " \"they're\": 'they are',\n",
    " \"they've\": 'they have',\n",
    " \"they'll\": 'they will',\n",
    " \"they'll've\": 'they will have',\n",
    " \"they'd\": 'they would',\n",
    " \"they'd've\": 'they would have',\n",
    " \"this's\": 'this is',\n",
    " \"those're\": 'those are',\n",
    " \"to've\": 'to have',\n",
    " 'wanna': 'want to',\n",
    " \"wasn't\": 'was not',\n",
    " \"we're\": 'we are',\n",
    " \"we've\": 'we have',\n",
    " \"we'll\": 'we will',\n",
    " \"we'll've\": 'we will have',\n",
    " \"we'd\": 'we would',\n",
    " \"we'd've\": 'we would have',\n",
    " \"weren't\": 'were not',\n",
    " \"what're\": 'what are',\n",
    " \"what'd\": 'what did',\n",
    " \"what've\": 'what have',\n",
    " \"what's\": 'what is',\n",
    " \"what'll\": 'what will',\n",
    " \"what'll've\": 'what will have',\n",
    " \"when've\": 'when have',\n",
    " \"when's\": 'when is',\n",
    " \"where're\": 'where are',\n",
    " \"where'd\": 'where did',\n",
    " \"where've\": 'where have',\n",
    " \"where's\": 'where is',\n",
    " \"which's\": 'which is',\n",
    " \"who're\": 'who are',\n",
    " \"who've\": 'who have',\n",
    " \"who's\": 'who is',\n",
    " \"who'll\": 'who will',\n",
    " \"who'll've\": 'who will have',\n",
    " \"who'd\": 'who would',\n",
    " \"who'd've\": 'who would have',\n",
    " \"why're\": 'why are',\n",
    " \"why'd\": 'why did',\n",
    " \"why've\": 'why have',\n",
    " \"why's\": 'why is',\n",
    " \"will've\": 'will have',\n",
    " \"won't\": 'will not',\n",
    " \"won't've\": 'will not have',\n",
    " \"would've\": 'would have',\n",
    " \"wouldn't\": 'would not',\n",
    " \"wouldn't've\": 'would not have',\n",
    " \"y'all\": 'you all',\n",
    " \"y'all're\": 'you all are',\n",
    " \"y'all've\": 'you all have',\n",
    " \"y'all'd\": 'you all would',\n",
    " \"y'all'd've\": 'you all would have',\n",
    " \"you're\": 'you are',\n",
    " \"you've\": 'you have',\n",
    " \"you'll've\": 'you shall have',\n",
    " \"you'll\": 'you will',\n",
    " \"you'd\": 'you would',\n",
    " \"you'd've\": 'you would have',\n",
    " 'jan.': 'january',\n",
    " 'feb.': 'february',\n",
    " 'mar.': 'march',\n",
    " 'apr.': 'april',\n",
    " 'jun.': 'june',\n",
    " 'jul.': 'july',\n",
    " 'aug.': 'august',\n",
    " 'sep.': 'september',\n",
    " 'oct.': 'october',\n",
    " 'nov.': 'november',\n",
    " 'dec.': 'december',\n",
    " 'I’m': 'I am',\n",
    " 'I’m’a': 'I am about to',\n",
    " 'I’m’o': 'I am going to',\n",
    " 'I’ve': 'I have',\n",
    " 'I’ll': 'I will',\n",
    " 'I’ll’ve': 'I will have',\n",
    " 'I’d': 'I would',\n",
    " 'I’d’ve': 'I would have',\n",
    " 'amn’t': 'am not',\n",
    " 'ain’t': 'are not',\n",
    " 'aren’t': 'are not',\n",
    " '’cause': 'because',\n",
    " 'can’t': 'can not',\n",
    " 'can’t’ve': 'can not have',\n",
    " 'could’ve': 'could have',\n",
    " 'couldn’t': 'could not',\n",
    " 'couldn’t’ve': 'could not have',\n",
    " 'daren’t': 'dare not',\n",
    " 'daresn’t': 'dare not',\n",
    " 'dasn’t': 'dare not',\n",
    " 'doesn’t': 'does not',\n",
    " 'e’er': 'ever',\n",
    " 'everyone’s': 'everyone is',\n",
    " 'gon’t': 'go not',\n",
    " 'hadn’t': 'had not',\n",
    " 'hadn’t’ve': 'had not have',\n",
    " 'hasn’t': 'has not',\n",
    " 'haven’t': 'have not',\n",
    " 'he’ve': 'he have',\n",
    " 'he’s': 'he is',\n",
    " 'he’ll': 'he will',\n",
    " 'he’ll’ve': 'he will have',\n",
    " 'he’d': 'he would',\n",
    " 'he’d’ve': 'he would have',\n",
    " 'here’s': 'here is',\n",
    " 'how’re': 'how are',\n",
    " 'how’d': 'how did',\n",
    " 'how’d’y': 'how do you',\n",
    " 'how’s': 'how is',\n",
    " 'how’ll': 'how will',\n",
    " 'isn’t': 'is not',\n",
    " 'it’s': 'it is',\n",
    " '’tis': 'it is',\n",
    " '’twas': 'it was',\n",
    " 'it’ll': 'it will',\n",
    " 'it’ll’ve': 'it will have',\n",
    " 'it’d': 'it would',\n",
    " 'it’d’ve': 'it would have',\n",
    " 'let’s': 'let us',\n",
    " 'ma’am': 'madam',\n",
    " 'may’ve': 'may have',\n",
    " 'mayn’t': 'may not',\n",
    " 'might’ve': 'might have',\n",
    " 'mightn’t': 'might not',\n",
    " 'mightn’t’ve': 'might not have',\n",
    " 'must’ve': 'must have',\n",
    " 'mustn’t': 'must not',\n",
    " 'mustn’t’ve': 'must not have',\n",
    " 'needn’t': 'need not',\n",
    " 'needn’t’ve': 'need not have',\n",
    " 'ne’er': 'never',\n",
    " 'o’': 'of',\n",
    " 'o’clock': 'of the clock',\n",
    " 'ol’': 'old',\n",
    " 'oughtn’t': 'ought not',\n",
    " 'oughtn’t’ve': 'ought not have',\n",
    " 'o’er': 'over',\n",
    " 'shan’t': 'shall not',\n",
    " 'sha’n’t': 'shall not',\n",
    " 'shalln’t': 'shall not',\n",
    " 'shan’t’ve': 'shall not have',\n",
    " 'she’s': 'she is',\n",
    " 'she’ll': 'she will',\n",
    " 'she’d': 'she would',\n",
    " 'she’d’ve': 'she would have',\n",
    " 'should’ve': 'should have',\n",
    " 'shouldn’t': 'should not',\n",
    " 'shouldn’t’ve': 'should not have',\n",
    " 'so’ve': 'so have',\n",
    " 'so’s': 'so is',\n",
    " 'somebody’s': 'somebody is',\n",
    " 'someone’s': 'someone is',\n",
    " 'something’s': 'something is',\n",
    " 'that’re': 'that are',\n",
    " 'that’s': 'that is',\n",
    " 'that’ll': 'that will',\n",
    " 'that’d': 'that would',\n",
    " 'that’d’ve': 'that would have',\n",
    " 'there’re': 'there are',\n",
    " 'there’s': 'there is',\n",
    " 'there’ll': 'there will',\n",
    " 'there’d': 'there would',\n",
    " 'there’d’ve': 'there would have',\n",
    " 'these’re': 'these are',\n",
    " 'they’re': 'they are',\n",
    " 'they’ve': 'they have',\n",
    " 'they’ll': 'they will',\n",
    " 'they’ll’ve': 'they will have',\n",
    " 'they’d': 'they would',\n",
    " 'they’d’ve': 'they would have',\n",
    " 'this’s': 'this is',\n",
    " 'those’re': 'those are',\n",
    " 'to’ve': 'to have',\n",
    " 'wasn’t': 'was not',\n",
    " 'we’re': 'we are',\n",
    " 'we’ve': 'we have',\n",
    " 'we’ll': 'we will',\n",
    " 'we’ll’ve': 'we will have',\n",
    " 'we’d': 'we would',\n",
    " 'we’d’ve': 'we would have',\n",
    " 'weren’t': 'were not',\n",
    " 'what’re': 'what are',\n",
    " 'what’d': 'what did',\n",
    " 'what’ve': 'what have',\n",
    " 'what’s': 'what is',\n",
    " 'what’ll': 'what will',\n",
    " 'what’ll’ve': 'what will have',\n",
    " 'when’ve': 'when have',\n",
    " 'when’s': 'when is',\n",
    " 'where’re': 'where are',\n",
    " 'where’d': 'where did',\n",
    " 'where’ve': 'where have',\n",
    " 'where’s': 'where is',\n",
    " 'which’s': 'which is',\n",
    " 'who’re': 'who are',\n",
    " 'who’ve': 'who have',\n",
    " 'who’s': 'who is',\n",
    " 'who’ll': 'who will',\n",
    " 'who’ll’ve': 'who will have',\n",
    " 'who’d': 'who would',\n",
    " 'who’d’ve': 'who would have',\n",
    " 'why’re': 'why are',\n",
    " 'why’d': 'why did',\n",
    " 'why’ve': 'why have',\n",
    " 'why’s': 'why is',\n",
    " 'will’ve': 'will have',\n",
    " 'won’t': 'will not',\n",
    " 'won’t’ve': 'will not have',\n",
    " 'would’ve': 'would have',\n",
    " 'wouldn’t': 'would not',\n",
    " 'wouldn’t’ve': 'would not have',\n",
    " 'y’all': 'you all',\n",
    " 'y’all’re': 'you all are',\n",
    " 'y’all’ve': 'you all have',\n",
    " 'y’all’d': 'you all would',\n",
    " 'y’all’d’ve': 'you all would have',\n",
    " 'you’re': 'you are',\n",
    " 'you’ve': 'you have',\n",
    " 'you’ll’ve': 'you shall have',\n",
    " 'you’ll': 'you will',\n",
    " 'you’d': 'you would',\n",
    " 'you’d’ve': 'you would have'}\n",
    "\n",
    "def contraction_fix(word):\n",
    "    try:\n",
    "        a=contractions[word]\n",
    "    except KeyError:\n",
    "        a=word\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:33:51.034893Z",
     "iopub.status.busy": "2021-02-09T18:33:51.033975Z",
     "iopub.status.idle": "2021-02-09T18:33:51.048949Z",
     "shell.execute_reply": "2021-02-09T18:33:51.054966Z"
    },
    "papermill": {
     "duration": 0.202063,
     "end_time": "2021-02-09T18:33:51.055209",
     "exception": false,
     "start_time": "2021-02-09T18:33:50.853146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Preprocess(doc):\n",
    "    corpus=[]\n",
    "    for text in tqdm(doc):\n",
    "        text=\" \".join([contraction_fix(w) for w in text.split()])\n",
    "        text=re.sub(r'[^a-z0-9A-Z]',\" \",text)\n",
    "        text=re.sub(r'[0-9]{1}',\"#\",text)\n",
    "        text=re.sub(r'[0-9]{2}','##',text)\n",
    "        text=re.sub(r'[0-9]{3}','###',text)\n",
    "        text=re.sub(r'[0-9]{4}','####',text)\n",
    "        text=re.sub(r'[0-9]{5,}','#####',text)\n",
    "        corpus.append(text)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:33:51.180321Z",
     "iopub.status.busy": "2021-02-09T18:33:51.179631Z",
     "iopub.status.idle": "2021-02-09T18:33:51.182630Z",
     "shell.execute_reply": "2021-02-09T18:33:51.182217Z"
    },
    "papermill": {
     "duration": 0.04986,
     "end_time": "2021-02-09T18:33:51.182745",
     "exception": false,
     "start_time": "2021-02-09T18:33:51.132885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## defining the vocabular function\n",
    "def get_vocab(corpus):\n",
    "    vocab={}\n",
    "    for text in tqdm(corpus):\n",
    "        for word in text.split():\n",
    "            try:\n",
    "                vocab[word]+=1\n",
    "            except KeyError:\n",
    "                vocab[word]=1\n",
    "    vocab=dict(sorted(vocab.items(),reverse=True ,key=lambda item: item[1]))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 22.651522,
     "end_time": "2021-02-09T18:34:13.863775",
     "exception": false,
     "start_time": "2021-02-09T18:33:51.212253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Expo 1.1 : without preprocessing + without pretrained Embeddings\n",
    "\n",
    "- here we are not going to do any preproess on text . just using the raw text.\n",
    "- Learning Embeddings during Trainig phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:34:13.928508Z",
     "iopub.status.busy": "2021-02-09T18:34:13.927980Z",
     "iopub.status.idle": "2021-02-09T18:34:18.783015Z",
     "shell.execute_reply": "2021-02-09T18:34:18.781791Z"
    },
    "papermill": {
     "duration": 4.889555,
     "end_time": "2021-02-09T18:34:18.783152",
     "exception": false,
     "start_time": "2021-02-09T18:34:13.893597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### importing the libraire\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D,GRU\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model,load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:34:18.850574Z",
     "iopub.status.busy": "2021-02-09T18:34:18.848708Z",
     "iopub.status.idle": "2021-02-09T18:34:18.851183Z",
     "shell.execute_reply": "2021-02-09T18:34:18.851602Z"
    },
    "papermill": {
     "duration": 0.037945,
     "end_time": "2021-02-09T18:34:18.851735",
     "exception": false,
     "start_time": "2021-02-09T18:34:18.813790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### defining the parameter\n",
    "max_feat=30000\n",
    "max_len=40\n",
    "feat_vec=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:34:18.923855Z",
     "iopub.status.busy": "2021-02-09T18:34:18.923240Z",
     "iopub.status.idle": "2021-02-09T18:34:18.926967Z",
     "shell.execute_reply": "2021-02-09T18:34:18.926450Z"
    },
    "papermill": {
     "duration": 0.043791,
     "end_time": "2021-02-09T18:34:18.927088",
     "exception": false,
     "start_time": "2021-02-09T18:34:18.883297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### gettting the index for the each word in vocabulary\n",
    "def get_word_index(vocab):\n",
    "    word_index=dict((w,i+1) for i,w in enumerate(vocab.keys()))\n",
    "    return word_index\n",
    "def fit_one_hot(word_index,corpus):\n",
    "    sent=[]\n",
    "    for text in tqdm(corpus):\n",
    "        li=[]\n",
    "        for word in text.split():\n",
    "            try:\n",
    "                li.append(word_index[word])\n",
    "            except KeyError:\n",
    "                li.append(0)\n",
    "        sent.append(li)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:34:18.997369Z",
     "iopub.status.busy": "2021-02-09T18:34:18.994915Z",
     "iopub.status.idle": "2021-02-09T18:34:38.685711Z",
     "shell.execute_reply": "2021-02-09T18:34:38.684515Z"
    },
    "papermill": {
     "duration": 19.727225,
     "end_time": "2021-02-09T18:34:38.685859",
     "exception": false,
     "start_time": "2021-02-09T18:34:18.958634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1044897/1044897 [00:04<00:00, 230899.65it/s]\n",
      "100%|██████████| 1044897/1044897 [00:06<00:00, 157459.55it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab=get_vocab(train.question_text)\n",
    "top_feat=dict(list(vocab.items())[:max_feat])\n",
    "word_index=get_word_index(top_feat)\n",
    "encoded_docs=fit_one_hot(word_index,train.question_text)\n",
    "padded_doc=pad_sequences(encoded_docs,maxlen=max_len,padding=\"post\")\n",
    "vocab_size=len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:34:38.800727Z",
     "iopub.status.busy": "2021-02-09T18:34:38.799914Z",
     "iopub.status.idle": "2021-02-09T18:34:42.322090Z",
     "shell.execute_reply": "2021-02-09T18:34:42.321621Z"
    },
    "papermill": {
     "duration": 3.58137,
     "end_time": "2021-02-09T18:34:42.322226",
     "exception": false,
     "start_time": "2021-02-09T18:34:38.740856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 261225/261225 [00:01<00:00, 161511.89it/s]\n"
     ]
    }
   ],
   "source": [
    "### getting the Validation data\n",
    "val_encodes=fit_one_hot(word_index,val.question_text)\n",
    "val_padded_doc=pad_sequences(val_encodes,maxlen=max_len,padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.057891,
     "end_time": "2021-02-09T18:34:42.438639",
     "exception": false,
     "start_time": "2021-02-09T18:34:42.380748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:34:42.563432Z",
     "iopub.status.busy": "2021-02-09T18:34:42.562796Z",
     "iopub.status.idle": "2021-02-09T18:34:45.533333Z",
     "shell.execute_reply": "2021-02-09T18:34:45.534056Z"
    },
    "papermill": {
     "duration": 3.03693,
     "end_time": "2021-02-09T18:34:45.534257",
     "exception": false,
     "start_time": "2021-02-09T18:34:42.497327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 40)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 40, 300)           9000300   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               140544    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 9,142,925\n",
      "Trainable params: 9,142,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(max_len,))\n",
    "x = Embedding(max_feat+1, feat_vec)(inp)\n",
    "x = Bidirectional(GRU(64, return_sequences=False))(x)\n",
    "#x = GlobalMaxPool1D()(x)\n",
    "x = Dense(16, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:34:45.656755Z",
     "iopub.status.busy": "2021-02-09T18:34:45.656276Z",
     "iopub.status.idle": "2021-02-09T18:34:45.660261Z",
     "shell.execute_reply": "2021-02-09T18:34:45.659816Z"
    },
    "papermill": {
     "duration": 0.067068,
     "end_time": "2021-02-09T18:34:45.660365",
     "exception": false,
     "start_time": "2021-02-09T18:34:45.593297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.fit(padded_doc, train.target, batch_size=128, epochs=2, validation_data=(val_padded_doc, val.target))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-09T18:34:45.781830Z",
     "iopub.status.busy": "2021-02-09T18:34:45.781326Z",
     "iopub.status.idle": "2021-02-09T18:34:45.786835Z",
     "shell.execute_reply": "2021-02-09T18:34:45.786414Z"
    },
    "papermill": {
     "duration": 0.068099,
     "end_time": "2021-02-09T18:34:45.786963",
     "exception": false,
     "start_time": "2021-02-09T18:34:45.718864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_pre=model.predict(val_padded_doc)\\nfor thresh in np.arange(0.1,0.5,0.01):\\n    print(\"threshold {0:2.2f} f1 score:{1}\".format(thresh,metrics.f1_score(val.target,(y_pre>thresh).astype(int))))\\n    \\n## saving the models\\nmodel.save(\"mode_noPre_lstm.h5\")\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "y_pre=model.predict(val_padded_doc)\n",
    "for thresh in np.arange(0.1,0.5,0.01):\n",
    "    print(\"threshold {0:2.2f} f1 score:{1}\".format(thresh,metrics.f1_score(val.target,(y_pre>thresh).astype(int))))\n",
    "    \n",
    "## saving the models\n",
    "model.save(\"mode_noPre_lstm.h5\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.059276,
     "end_time": "2021-02-09T18:34:45.905795",
     "exception": false,
     "start_time": "2021-02-09T18:34:45.846519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Exper 1.2 preprocessing + without pretrained\n",
    "\n",
    "- By doing preprocessing i am thinking that there will be reduce some unnecessary terms here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:34:46.028323Z",
     "iopub.status.busy": "2021-02-09T18:34:46.027634Z",
     "iopub.status.idle": "2021-02-09T18:34:46.030762Z",
     "shell.execute_reply": "2021-02-09T18:34:46.030360Z"
    },
    "papermill": {
     "duration": 0.065598,
     "end_time": "2021-02-09T18:34:46.030867",
     "exception": false,
     "start_time": "2021-02-09T18:34:45.965269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### defining the parameter\n",
    "max_feat=30000\n",
    "max_len=40\n",
    "feat_vec=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:34:46.155231Z",
     "iopub.status.busy": "2021-02-09T18:34:46.154448Z",
     "iopub.status.idle": "2021-02-09T18:35:52.091512Z",
     "shell.execute_reply": "2021-02-09T18:35:52.090824Z"
    },
    "papermill": {
     "duration": 66.0015,
     "end_time": "2021-02-09T18:35:52.091653",
     "exception": false,
     "start_time": "2021-02-09T18:34:46.090153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1044897/1044897 [00:35<00:00, 29373.72it/s]\n",
      "100%|██████████| 261225/261225 [00:08<00:00, 30330.95it/s]\n",
      "100%|██████████| 1044897/1044897 [00:04<00:00, 251836.54it/s]\n",
      "100%|██████████| 1044897/1044897 [00:05<00:00, 174433.48it/s]\n",
      "100%|██████████| 261225/261225 [00:01<00:00, 151762.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 746 ms, total: 1min 6s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### preprocessing the text\n",
    "train_text=Preprocess(train.question_text)\n",
    "val_text=Preprocess(val.question_text)\n",
    "\n",
    "\n",
    "vocab=get_vocab(train_text)\n",
    "top_feat=dict(list(vocab.items())[:max_feat])\n",
    "word_index=get_word_index(top_feat)\n",
    "\n",
    "### encoding the training set\n",
    "encoded_docs=fit_one_hot(word_index,train_text)\n",
    "padded_doc=pad_sequences(encoded_docs,maxlen=max_len,padding=\"post\")\n",
    "\n",
    "### encoding the Validation set\n",
    "encoded_docs=fit_one_hot(word_index,val_text)\n",
    "val_padded_doc=pad_sequences(encoded_docs,maxlen=max_len,padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.196317,
     "end_time": "2021-02-09T18:35:52.483366",
     "exception": false,
     "start_time": "2021-02-09T18:35:52.287049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:35:52.884373Z",
     "iopub.status.busy": "2021-02-09T18:35:52.883653Z",
     "iopub.status.idle": "2021-02-09T18:35:53.340445Z",
     "shell.execute_reply": "2021-02-09T18:35:53.341081Z"
    },
    "papermill": {
     "duration": 0.660542,
     "end_time": "2021-02-09T18:35:53.341327",
     "exception": false,
     "start_time": "2021-02-09T18:35:52.680785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 40)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 40, 300)           9000300   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 40, 256)           330240    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 36, 64)            81984     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 9,420,973\n",
      "Trainable params: 9,420,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(max_len,))\n",
    "x = Embedding(max_feat+1, feat_vec)(inp)\n",
    "x = Bidirectional(GRU(128, return_sequences=True))(x)\n",
    "x = Conv1D(64,5,activation=\"relu\")(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:35:53.930353Z",
     "iopub.status.busy": "2021-02-09T18:35:53.929369Z",
     "iopub.status.idle": "2021-02-09T18:35:53.933311Z",
     "shell.execute_reply": "2021-02-09T18:35:53.934414Z"
    },
    "papermill": {
     "duration": 0.347453,
     "end_time": "2021-02-09T18:35:53.934618",
     "exception": false,
     "start_time": "2021-02-09T18:35:53.587165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### defining some callbacks\n",
    "opt=Adam(learning_rate=0.002)\n",
    "bin_loss=tf.keras.losses.BinaryCrossentropy(\n",
    "                                            from_logits=False, \n",
    "                                            label_smoothing=0.2,\n",
    "                                            name='binary_crossentropy'\n",
    "                                        )\n",
    "\n",
    "## defining the call backs\n",
    "early_stopping=tf.keras.callbacks.EarlyStopping(\n",
    "                                                monitor=\"val_loss\",\n",
    "                                                patience=3,\n",
    "                                                mode=\"min\",\n",
    "                                                restore_best_weights=True\n",
    "                                              )\n",
    "### Now reducing the learning rate when the model is not improvinig \n",
    "reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                                                monitor=\"val_loss\",\n",
    "                                                factor=0.2,\n",
    "                                                patience=2,\n",
    "                                                verbose=1,\n",
    "                                                mode=\"auto\"\n",
    "                                            )\n",
    "\n",
    "my_callbacks=[early_stopping,reduce_lr]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:35:54.408846Z",
     "iopub.status.busy": "2021-02-09T18:35:54.408320Z",
     "iopub.status.idle": "2021-02-09T18:35:54.414866Z",
     "shell.execute_reply": "2021-02-09T18:35:54.414425Z"
    },
    "papermill": {
     "duration": 0.211293,
     "end_time": "2021-02-09T18:35:54.415001",
     "exception": false,
     "start_time": "2021-02-09T18:35:54.203708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss=bin_loss, optimizer=\"adam\", metrics=['accuracy'])\n",
    "#model.fit(padded_doc, train.target, batch_size=512, epochs=2, validation_data=(val_padded_doc, val.target),callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2021-02-09T18:35:54.813646Z",
     "iopub.status.busy": "2021-02-09T18:35:54.812874Z",
     "iopub.status.idle": "2021-02-09T18:35:54.816181Z",
     "shell.execute_reply": "2021-02-09T18:35:54.816582Z"
    },
    "papermill": {
     "duration": 0.20641,
     "end_time": "2021-02-09T18:35:54.816711",
     "exception": false,
     "start_time": "2021-02-09T18:35:54.610301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny_pre=model.predict(val_padded_doc)\\nfor thresh in np.arange(0.1,0.5,0.01):\\n    print(\"threshold {0:2.2f} f1 score:{1:2.3f}\".format(thresh,metrics.f1_score(val.target,(y_pre>thresh).astype(int))))\\n    \\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "y_pre=model.predict(val_padded_doc)\n",
    "for thresh in np.arange(0.1,0.5,0.01):\n",
    "    print(\"threshold {0:2.2f} f1 score:{1:2.3f}\".format(thresh,metrics.f1_score(val.target,(y_pre>thresh).astype(int))))\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:35:55.215121Z",
     "iopub.status.busy": "2021-02-09T18:35:55.214414Z",
     "iopub.status.idle": "2021-02-09T18:35:55.217320Z",
     "shell.execute_reply": "2021-02-09T18:35:55.216778Z"
    },
    "papermill": {
     "duration": 0.202819,
     "end_time": "2021-02-09T18:35:55.217428",
     "exception": false,
     "start_time": "2021-02-09T18:35:55.014609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## saving the models\n",
    "#model.save(\"mode_Pre_lstm.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.196266,
     "end_time": "2021-02-09T18:35:55.609082",
     "exception": false,
     "start_time": "2021-02-09T18:35:55.412816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Experiment 2: Pretrained Embeddings + LSTM\n",
    "- Here I am using the GOOGle News as pretrained Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.209548,
     "end_time": "2021-02-09T18:35:56.014543",
     "exception": false,
     "start_time": "2021-02-09T18:35:55.804995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### HOw much percentage that covered of Entire Corpus\n",
    "- Here we check for the each pretrained Embeddings \n",
    "- Do processing that will conver much embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.196635,
     "end_time": "2021-02-09T18:35:56.407841",
     "exception": false,
     "start_time": "2021-02-09T18:35:56.211206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2.1 LOading and Checking the Pretrained Embeddings (GOOGLE NEWS DATA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:35:56.808111Z",
     "iopub.status.busy": "2021-02-09T18:35:56.807479Z",
     "iopub.status.idle": "2021-02-09T18:36:37.501311Z",
     "shell.execute_reply": "2021-02-09T18:36:37.502286Z"
    },
    "papermill": {
     "duration": 40.899347,
     "end_time": "2021-02-09T18:36:37.502564",
     "exception": false,
     "start_time": "2021-02-09T18:35:56.603217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.5 s, sys: 3.71 s, total: 29.2 s\n",
      "Wall time: 40.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Loading the Google News Pretrained Embeddings\n",
    "file_name=\"./GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\"\n",
    "model_embed=KeyedVectors.load_word2vec_format(file_name,binary=True)\n",
    "\n",
    "### Building the Vocabulary \n",
    "def vocab_build(corpus):\n",
    "    vocab={}\n",
    "    for text in tqdm(corpus):\n",
    "        for word in text.split():\n",
    "            try:\n",
    "                vocab[word]+=1\n",
    "            except KeyError:\n",
    "                vocab[word]=1\n",
    "    return vocab\n",
    "\n",
    "\n",
    "### Checking the Vocabulary That how much percentage of Vocabulary was covered \n",
    "def check_voc(vocab,model):\n",
    "    embed_words=[]\n",
    "    out_vocab={}\n",
    "    total_words=0\n",
    "    total_text=0\n",
    "    for i in tqdm(vocab):\n",
    "        try:\n",
    "            vec=model[i]\n",
    "            embed_words.append(vec)\n",
    "            total_words+=vocab[i]\n",
    "        except KeyError:\n",
    "            out_vocab[i]=vocab[i]\n",
    "            total_text+=vocab[i]\n",
    "    print(\"The {:.2f}% of vocabularies have Covered of corpus\".format(100*len(embed_words)/len(vocab)))\n",
    "    print(\"The {:.2f}% of total text had coverded \".format((100*total_words/(total_words+total_text))))\n",
    "    return out_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:36:38.188330Z",
     "iopub.status.busy": "2021-02-09T18:36:38.186826Z",
     "iopub.status.idle": "2021-02-09T18:36:47.221851Z",
     "shell.execute_reply": "2021-02-09T18:36:47.222426Z"
    },
    "papermill": {
     "duration": 9.347553,
     "end_time": "2021-02-09T18:36:47.222607",
     "exception": false,
     "start_time": "2021-02-09T18:36:37.875054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1681928/1681928 [00:07<00:00, 227510.40it/s]\n",
      "100%|██████████| 597383/597383 [00:01<00:00, 379869.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 22.79% of vocabularies have Covered of corpus\n",
      "The 78.75% of total text had coverded \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### here we are concatenating the both the training and validation dataset\n",
    "### building the vocabulary and checking coverage of vocabulary\n",
    "total_text=pd.concat([train_data.question_text,test_data.question_text])\n",
    "vocabulary=vocab_build(total_text)\n",
    "oov=check_voc(vocabulary,model_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.221198,
     "end_time": "2021-02-09T18:36:47.663460",
     "exception": false,
     "start_time": "2021-02-09T18:36:47.442262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Lets Analyze\n",
    "- We observed that there will less amount of vocabulary was covered\n",
    "- now we wiil analyze the out of vocabulary.\n",
    "- to increase the coverage we will do preprocess the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:36:48.431756Z",
     "iopub.status.busy": "2021-02-09T18:36:48.354084Z",
     "iopub.status.idle": "2021-02-09T18:36:48.434710Z",
     "shell.execute_reply": "2021-02-09T18:36:48.435169Z"
    },
    "papermill": {
     "duration": 0.550588,
     "end_time": "2021-02-09T18:36:48.435319",
     "exception": false,
     "start_time": "2021-02-09T18:36:47.884731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 519436,\n",
       " 'a': 518220,\n",
       " 'of': 426037,\n",
       " 'and': 324657,\n",
       " 'India?': 21063,\n",
       " 'it?': 16623,\n",
       " 'do?': 11211,\n",
       " 'life?': 9993,\n",
       " 'you?': 8083,\n",
       " 'me?': 7982,\n",
       " 'them?': 7910,\n",
       " 'time?': 7379,\n",
       " 'world?': 6941,\n",
       " 'people?': 6472,\n",
       " 'why?': 6353,\n",
       " 'Quora?': 5972,\n",
       " '10': 5872,\n",
       " 'like?': 5720,\n",
       " 'for?': 5706,\n",
       " 'work?': 5411,\n",
       " '2017?': 5171,\n",
       " 'mean?': 5101,\n",
       " '2018?': 4618,\n",
       " 'country?': 4441,\n",
       " 'now?': 4289,\n",
       " 'this?': 4280,\n",
       " 'years?': 4167,\n",
       " '2017': 4075,\n",
       " 'not?': 4000,\n",
       " 'year?': 3597,\n",
       " '2018': 3573,\n",
       " 'day?': 3511,\n",
       " 'engineering?': 3335,\n",
       " 'person?': 3313,\n",
       " 'school?': 3294,\n",
       " 'so,': 3290,\n",
       " '-': 3250,\n",
       " 'I’m': 3165,\n",
       " 'system?': 3130,\n",
       " '12': 3128,\n",
       " 'money?': 3115,\n",
       " 'be?': 3100,\n",
       " 'today?': 3086,\n",
       " 'Why?': 3076,\n",
       " 'China?': 3069,\n",
       " 'job?': 3003,\n",
       " 'business?': 2958,\n",
       " 'company?': 2880,\n",
       " '\"The': 2875,\n",
       " 'him?': 2827}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_oov=dict(sorted(oov.items(), key=operator.itemgetter(1),reverse=True))\n",
    "dict(list(sort_oov.items())[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.356101,
     "end_time": "2021-02-09T18:36:49.154852",
     "exception": false,
     "start_time": "2021-02-09T18:36:48.798751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Observations**\n",
    "- some of the puncutation marks are not in pretrained embeedings\n",
    "- May be the raw numbers are in the form of other type\n",
    "- Question mark is followed by the word so we need to seperate that and that too question mark doesn't have a embedding.\n",
    "- Some preprosition too doesn't have the embeddings like (a,to,of and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:36:50.434413Z",
     "iopub.status.busy": "2021-02-09T18:36:50.433633Z",
     "iopub.status.idle": "2021-02-09T18:36:50.437375Z",
     "shell.execute_reply": "2021-02-09T18:36:50.437780Z"
    },
    "papermill": {
     "duration": 1.054714,
     "end_time": "2021-02-09T18:36:50.437943",
     "exception": false,
     "start_time": "2021-02-09T18:36:49.383229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del oov,vocabulary,sort_oov\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:36:50.920328Z",
     "iopub.status.busy": "2021-02-09T18:36:50.919537Z",
     "iopub.status.idle": "2021-02-09T18:37:54.514833Z",
     "shell.execute_reply": "2021-02-09T18:37:54.516168Z"
    },
    "papermill": {
     "duration": 63.832353,
     "end_time": "2021-02-09T18:37:54.517044",
     "exception": false,
     "start_time": "2021-02-09T18:36:50.684691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1681928/1681928 [00:56<00:00, 29781.73it/s]\n",
      "100%|██████████| 1681928/1681928 [00:06<00:00, 265509.29it/s]\n",
      "100%|██████████| 258744/258744 [00:00<00:00, 349906.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 61.35% of vocabularies have Covered of corpus\n",
      "The 90.79% of total text had coverded \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### lets try to resolve above problems by preprocessing it \n",
    "pre_text=Preprocess(total_text)\n",
    "vocabulary=vocab_build(pre_text)\n",
    "oov=check_voc(vocabulary,model_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:37:55.696408Z",
     "iopub.status.busy": "2021-02-09T18:37:55.695650Z",
     "iopub.status.idle": "2021-02-09T18:37:55.699619Z",
     "shell.execute_reply": "2021-02-09T18:37:55.699197Z"
    },
    "papermill": {
     "duration": 0.534243,
     "end_time": "2021-02-09T18:37:55.699743",
     "exception": false,
     "start_time": "2021-02-09T18:37:55.165500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 524305,\n",
       " 'a': 520961,\n",
       " 'of': 428914,\n",
       " 'and': 327505,\n",
       " '#th': 2528,\n",
       " 'WW#': 1803,\n",
       " 'favourite': 1639,\n",
       " '#st': 1497,\n",
       " '#D': 1392,\n",
       " '#x': 1385,\n",
       " '#nd': 1335,\n",
       " 'bitcoin': 1296,\n",
       " 'colour': 1271,\n",
       " 'centre': 1114,\n",
       " 'Quorans': 1061,\n",
       " 'cryptocurrency': 1040,\n",
       " 'Snapchat': 1030,\n",
       " '#rd': 910,\n",
       " 'travelling': 893,\n",
       " 'counselling': 824,\n",
       " '#G': 737,\n",
       " 'Brexit': 639,\n",
       " 'blockchain': 632,\n",
       " 'btech': 610,\n",
       " 'cryptocurrencies': 602,\n",
       " 'behaviour': 589,\n",
       " 'PS#': 573,\n",
       " 'upvotes': 557,\n",
       " '#k': 554,\n",
       " 'S#': 534,\n",
       " 'programme': 506,\n",
       " 'F#': 490,\n",
       " 'i#': 489,\n",
       " 'realise': 485,\n",
       " 'Redmi': 483,\n",
       " 'defence': 459,\n",
       " '#s': 454,\n",
       " 'Paytm': 434,\n",
       " 'KVPY': 432,\n",
       " 'B#': 431,\n",
       " 'A#': 414,\n",
       " 'H#B': 387,\n",
       " 'organisation': 384,\n",
       " 'grey': 380,\n",
       " 'cancelled': 377,\n",
       " 'B#B': 336,\n",
       " 'learnt': 330,\n",
       " 'H#': 330,\n",
       " 'honours': 328,\n",
       " 'licence': 320}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_oov=dict(sorted(oov.items(), key=operator.itemgetter(1),reverse=True))\n",
    "dict(list(sort_oov.items())[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.377228,
     "end_time": "2021-02-09T18:37:56.457717",
     "exception": false,
     "start_time": "2021-02-09T18:37:56.080489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- here i am ending this here .\n",
    "\n",
    "**Furthur Preprocessing is Required**\n",
    "- Spell correction mainly \n",
    "- Some word doesn't have a embeddings in a pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:37:58.051292Z",
     "iopub.status.busy": "2021-02-09T18:37:58.050314Z",
     "iopub.status.idle": "2021-02-09T18:37:58.054963Z",
     "shell.execute_reply": "2021-02-09T18:37:58.054510Z"
    },
    "papermill": {
     "duration": 1.220056,
     "end_time": "2021-02-09T18:37:58.055085",
     "exception": false,
     "start_time": "2021-02-09T18:37:56.835029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del oov,pre_text,sort_oov,total_text\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:37:58.887084Z",
     "iopub.status.busy": "2021-02-09T18:37:58.862392Z",
     "iopub.status.idle": "2021-02-09T18:39:16.665435Z",
     "shell.execute_reply": "2021-02-09T18:39:16.664979Z"
    },
    "papermill": {
     "duration": 78.221675,
     "end_time": "2021-02-09T18:39:16.665570",
     "exception": false,
     "start_time": "2021-02-09T18:37:58.443895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1044897/1044897 [00:35<00:00, 29644.94it/s]\n",
      "100%|██████████| 261225/261225 [00:08<00:00, 30208.28it/s]\n",
      "100%|██████████| 375806/375806 [00:12<00:00, 29234.69it/s]\n",
      "100%|██████████| 1044897/1044897 [00:05<00:00, 176200.49it/s]\n",
      "100%|██████████| 261225/261225 [00:01<00:00, 233709.86it/s]\n",
      "100%|██████████| 375806/375806 [00:01<00:00, 243703.40it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab_size=len(vocabulary)+1\n",
    "max_len=40\n",
    "\n",
    "word_index=get_word_index(vocabulary)\n",
    "### preprocess the data\n",
    "train_text=Preprocess(train.question_text)\n",
    "val_text=Preprocess(val.question_text)\n",
    "test_text=Preprocess(test_data.question_text)\n",
    "\n",
    "### encoding the training data\n",
    "encodes=fit_one_hot(word_index,train_text)\n",
    "train_padded=pad_sequences(encodes,maxlen=max_len,padding=\"post\")\n",
    "\n",
    "### encoding the validation_data\n",
    "encodes_=fit_one_hot(word_index,val_text)\n",
    "val_padded=pad_sequences(encodes_,maxlen=max_len,padding=\"post\")\n",
    "\n",
    "### encoding the testing_data\n",
    "encodes__=fit_one_hot(word_index,test_text)\n",
    "test_padded=pad_sequences(encodes__,maxlen=max_len,padding=\"post\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.536642,
     "end_time": "2021-02-09T18:39:17.742566",
     "exception": false,
     "start_time": "2021-02-09T18:39:17.205924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Constructing the Embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:39:18.858024Z",
     "iopub.status.busy": "2021-02-09T18:39:18.857086Z",
     "iopub.status.idle": "2021-02-09T18:39:20.202150Z",
     "shell.execute_reply": "2021-02-09T18:39:20.200530Z"
    },
    "papermill": {
     "duration": 1.917452,
     "end_time": "2021-02-09T18:39:20.202372",
     "exception": false,
     "start_time": "2021-02-09T18:39:18.284920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258744/258744 [00:01<00:00, 193614.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Out of Vocabulary 100008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## step 3: constructinng embedding matrix for the corpus vocabulary using the pretrained embeddings:\n",
    "## here each row will have the emedding vector for each unique word\n",
    "count=0\n",
    "embedding_mat=np.zeros((vocab_size,300))\n",
    "for word,i in tqdm(word_index.items()):\n",
    "    try:\n",
    "        vec=model_embed[word]\n",
    "        embedding_mat[i]=vec\n",
    "    except KeyError:\n",
    "        count+=1\n",
    "        continue\n",
    "\n",
    "print(\"Number of Out of Vocabulary\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:39:21.336387Z",
     "iopub.status.busy": "2021-02-09T18:39:21.335562Z",
     "iopub.status.idle": "2021-02-09T18:39:23.704439Z",
     "shell.execute_reply": "2021-02-09T18:39:23.705032Z"
    },
    "papermill": {
     "duration": 2.927608,
     "end_time": "2021-02-09T18:39:23.705211",
     "exception": false,
     "start_time": "2021-02-09T18:39:20.777603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 40)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 40, 300)           77623500  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 40, 256)           439296    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 38, 64)            49216     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 78,120,461\n",
      "Trainable params: 496,961\n",
      "Non-trainable params: 77,623,500\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(max_len,))\n",
    "x = Embedding(vocab_size,300,weights=[embedding_mat],input_length=max_len,trainable=False)(inp)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "x = Conv1D(64,3,activation=\"relu\")(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:39:24.802901Z",
     "iopub.status.busy": "2021-02-09T18:39:24.802191Z",
     "iopub.status.idle": "2021-02-09T18:39:24.806066Z",
     "shell.execute_reply": "2021-02-09T18:39:24.805565Z"
    },
    "papermill": {
     "duration": 0.557873,
     "end_time": "2021-02-09T18:39:24.806190",
     "exception": false,
     "start_time": "2021-02-09T18:39:24.248317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt=Adam(learning_rate=0.001)\n",
    "bin_loss=tf.keras.losses.BinaryCrossentropy(\n",
    "                                            from_logits=False, \n",
    "                                            label_smoothing=0,\n",
    "                                            name='binary_crossentropy'\n",
    "                                        )\n",
    "\n",
    "## defining the call backs\n",
    "early_stopping=tf.keras.callbacks.EarlyStopping(\n",
    "                                                monitor=\"val_loss\",\n",
    "                                                patience=3,\n",
    "                                                mode=\"min\",\n",
    "                                                restore_best_weights=True\n",
    "                                              )\n",
    "### Now reducing the learning rate when the model is not improvinig \n",
    "reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                                                monitor=\"val_loss\",\n",
    "                                                factor=0.2,\n",
    "                                                patience=2,\n",
    "                                                verbose=1,\n",
    "                                                mode=\"auto\"\n",
    "                                            )\n",
    "\n",
    "my_callbacks=[early_stopping,reduce_lr]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:39:25.960988Z",
     "iopub.status.busy": "2021-02-09T18:39:25.960178Z",
     "iopub.status.idle": "2021-02-09T18:43:53.800740Z",
     "shell.execute_reply": "2021-02-09T18:43:53.800310Z"
    },
    "papermill": {
     "duration": 268.438217,
     "end_time": "2021-02-09T18:43:53.800869",
     "exception": false,
     "start_time": "2021-02-09T18:39:25.362652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2041/2041 [==============================] - 71s 32ms/step - loss: 0.1376 - accuracy: 0.9483 - val_loss: 0.1080 - val_accuracy: 0.9569\n",
      "Epoch 2/4\n",
      "2041/2041 [==============================] - 65s 32ms/step - loss: 0.1055 - accuracy: 0.9580 - val_loss: 0.1034 - val_accuracy: 0.9589\n",
      "Epoch 3/4\n",
      "2041/2041 [==============================] - 65s 32ms/step - loss: 0.0984 - accuracy: 0.9608 - val_loss: 0.1004 - val_accuracy: 0.9600\n",
      "Epoch 4/4\n",
      "2041/2041 [==============================] - 65s 32ms/step - loss: 0.0930 - accuracy: 0.9627 - val_loss: 0.1012 - val_accuracy: 0.9603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9cd4aa4750>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=bin_loss, optimizer=opt, metrics=['accuracy'])\n",
    "model.fit(train_padded, train.target, batch_size=512, epochs=4, validation_data=(val_padded, val.target),callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:43:56.982732Z",
     "iopub.status.busy": "2021-02-09T18:43:56.982161Z",
     "iopub.status.idle": "2021-02-09T18:44:26.644012Z",
     "shell.execute_reply": "2021-02-09T18:44:26.643327Z"
    },
    "papermill": {
     "duration": 31.253164,
     "end_time": "2021-02-09T18:44:26.644188",
     "exception": false,
     "start_time": "2021-02-09T18:43:55.391024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.10 f1 score:0.624\n",
      "threshold 0.11 f1 score:0.630\n",
      "threshold 0.12 f1 score:0.636\n",
      "threshold 0.13 f1 score:0.641\n",
      "threshold 0.14 f1 score:0.646\n",
      "threshold 0.15 f1 score:0.649\n",
      "threshold 0.16 f1 score:0.653\n",
      "threshold 0.17 f1 score:0.657\n",
      "threshold 0.18 f1 score:0.660\n",
      "threshold 0.19 f1 score:0.662\n",
      "threshold 0.20 f1 score:0.665\n",
      "threshold 0.21 f1 score:0.666\n",
      "threshold 0.22 f1 score:0.668\n",
      "threshold 0.23 f1 score:0.669\n",
      "threshold 0.24 f1 score:0.670\n",
      "threshold 0.25 f1 score:0.671\n",
      "threshold 0.26 f1 score:0.672\n",
      "threshold 0.27 f1 score:0.672\n",
      "threshold 0.28 f1 score:0.672\n",
      "threshold 0.29 f1 score:0.672\n",
      "threshold 0.30 f1 score:0.672\n",
      "threshold 0.31 f1 score:0.672\n",
      "threshold 0.32 f1 score:0.673\n",
      "threshold 0.33 f1 score:0.673\n",
      "threshold 0.34 f1 score:0.672\n",
      "threshold 0.35 f1 score:0.672\n",
      "threshold 0.36 f1 score:0.671\n",
      "threshold 0.37 f1 score:0.671\n",
      "threshold 0.38 f1 score:0.670\n",
      "threshold 0.39 f1 score:0.669\n",
      "threshold 0.40 f1 score:0.667\n",
      "threshold 0.41 f1 score:0.666\n",
      "threshold 0.42 f1 score:0.665\n",
      "threshold 0.43 f1 score:0.664\n",
      "threshold 0.44 f1 score:0.661\n",
      "threshold 0.45 f1 score:0.659\n",
      "threshold 0.46 f1 score:0.656\n",
      "threshold 0.47 f1 score:0.654\n",
      "threshold 0.48 f1 score:0.651\n",
      "threshold 0.49 f1 score:0.647\n"
     ]
    }
   ],
   "source": [
    "y_pre=model.predict(val_padded)\n",
    "for thresh in np.arange(0.1,0.5,0.01):\n",
    "    print(\"threshold {0:2.2f} f1 score:{1:2.3f}\".format(thresh,metrics.f1_score(val.target,(y_pre>thresh).astype(int))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T18:44:29.869434Z",
     "iopub.status.busy": "2021-02-09T18:44:29.868471Z",
     "iopub.status.idle": "2021-02-09T18:45:08.439540Z",
     "shell.execute_reply": "2021-02-09T18:45:08.439071Z"
    },
    "papermill": {
     "duration": 40.173527,
     "end_time": "2021-02-09T18:45:08.439675",
     "exception": false,
     "start_time": "2021-02-09T18:44:28.266148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### INference the Test data\n",
    "\n",
    "threshold=0.36\n",
    "y_test_pre=model.predict(test_padded)\n",
    "y_test_pre=(y_test_pre>thresh).astype(int)\n",
    "\n",
    "### Creating the submission File\n",
    "submit=pd.DataFrame()\n",
    "submit[\"qid\"]=test_data.qid\n",
    "submit[\"prediction\"]=y_test_pre\n",
    "submit.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.643577,
     "end_time": "2021-02-09T18:45:11.724561",
     "exception": false,
     "start_time": "2021-02-09T18:45:10.080984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 928.658967,
   "end_time": "2021-02-09T18:45:19.129152",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-09T18:29:50.470185",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
